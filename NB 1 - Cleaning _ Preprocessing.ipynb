{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUWQKotSmZ6v"
   },
   "source": [
    "## ðŸŽ¯Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1670165306246,
     "user": {
      "displayName": "Caladarmi",
      "userId": "17421711288101718877"
     },
     "user_tz": -60
    },
    "id": "frW-uIuPmZ6x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUUy7yO9mZ6y"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('nigeria-rent.csv')\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOrlx3oBmZ6z"
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'More Info':'Description'}, inplace = True)\n",
    "df.rename(columns = {'Title':'Real Estate Agent Tag'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKSJ6Na0mZ6z"
   },
   "outputs": [],
   "source": [
    "## Removing non-residential properties\n",
    "\n",
    "# Search \"Description\" Column for Keywords\n",
    "df['Description'].unique()\n",
    "\n",
    "# Remove all observations that are in any way non-residential property by searching for red-flag keywords\n",
    "df_a1 = df.loc[df['Description'].str.contains('COMMERCIAL', case=False)]\n",
    "df_a2 = pd.concat([df,df_a1]).drop_duplicates(keep=False)\n",
    "\n",
    "df_b1 = df_a2.loc[df['Description'].str.contains('OFFICE', case=False)]\n",
    "df_b2 = pd.concat([df_a2,df_b1]).drop_duplicates(keep=False)\n",
    "\n",
    "df_c1 = df_b2.loc[df['Description'].str.contains('WORKING', case=False)]\n",
    "df_c2 = pd.concat([df_b2,df_c1]).drop_duplicates(keep=False)\n",
    "\n",
    "df_d1 = df_c2.loc[df['Description'].str.contains('LAND', case=False)]\n",
    "df_d2 = pd.concat([df_c2,df_d1]).drop_duplicates(keep=False)\n",
    "\n",
    "df_e1 = df_d2.loc[df['Description'].str.contains('JOINT VENTURE', case=False)]\n",
    "df_e2 = pd.concat([df_d2,df_e1]).drop_duplicates(keep=False)\n",
    "\n",
    "df_f1 = df_e2.loc[df['Description'].str.contains('CONFERENCE', case=False)]\n",
    "df_f2 = pd.concat([df_e2,df_f1]).drop_duplicates(keep=False)\n",
    "\n",
    "# This isn't totally sufficient; let's also only keep observations with \"Bedroom\" in the description string\n",
    "df_cd = df_f2.loc[df['Description'].str.contains('BEDROOM', case=False)]\n",
    "df_cd['Description'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvasA82EmZ60"
   },
   "outputs": [],
   "source": [
    "# Extracting additoinal information from the 'Description' column\n",
    "\n",
    "# Create binary true/false columns for 'Duplex', 'Terraced', 'Detached' and 'Penthouse'\n",
    "df_duplex = df_cd.loc[df_cd['Description'].str.contains('DUPLEX', case=False)]\n",
    "duplexindexes = df_duplex.index.to_list()\n",
    "df_cd['Duplex'] = 0\n",
    "df_cd.loc[duplexindexes, 'Duplex'] = 1\n",
    "\n",
    "df_terraced = df_cd.loc[df_cd['Description'].str.contains('TERRACED', case=False)]\n",
    "terracedindexes = df_terraced.index.to_list()\n",
    "df_cd['Terraced'] = 0\n",
    "df_cd.loc[terracedindexes, 'Terraced'] = 1\n",
    "\n",
    "df_detached = df_cd.loc[df_cd['Description'].str.contains('DETACHED', case=False)]\n",
    "detachedindexes = df_detached.index.to_list()\n",
    "df_cd['Detached'] = 0\n",
    "df_cd.loc[detachedindexes, 'Detached'] = 1\n",
    "\n",
    "df_penthouse = df_cd.loc[df_cd['Description'].str.contains('PENTHOUSE', case=False)]\n",
    "penthouseindexes = df_penthouse.index.to_list()\n",
    "df_cd['Penthouse'] = 0\n",
    "df_cd.loc[penthouseindexes, 'Penthouse'] = 1\n",
    "\n",
    "df_apartment = df_cd.loc[df_cd['Description'].str.contains('APARTMENT', case=False)]\n",
    "df_flat = df_cd.loc[df_cd['Description'].str.contains('FLAT', case=False)]\n",
    "apartmentindexes = df_apartment.index.to_list()\n",
    "flatindexes = df_flat.index.to_list()\n",
    "df_cd['Apartment'] = 0\n",
    "df_cd.loc[apartmentindexes, 'Apartment'] = 1\n",
    "df_cd.loc[flatindexes, 'Apartment'] = 1\n",
    "\n",
    "# Sidenote: all entries that are not apartments or flats must be houses, hence: \n",
    "df_cd['House'] = 1\n",
    "df_cd.loc[apartmentindexes, 'House'] = 0\n",
    "\n",
    "# Search the Dataframe for attachment keywords and drop all that have no valid attachment type (terraced, detached, semi-detached)\n",
    "df_detached = df_cd.loc[df_cd['Description'].str.contains('DETACHED', case=False)]\n",
    "detachedindexes2 = df_detached.index.to_list()\n",
    "df_terraced = df_cd.loc[df_cd['Description'].str.contains('TERRACED', case=False)]\n",
    "terracedindexes2 = df_terraced.index.to_list()\n",
    "attachmenttype = detachedindexes2 + terracedindexes2\n",
    "df_clean = df_cd.loc[attachmenttype]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_u1azeUmZ60"
   },
   "outputs": [],
   "source": [
    "# Eliminating penthouse column\n",
    "\n",
    "# The above cleaning cell removed all observations that were penthouses, so this feature is irrelevant now. \n",
    "df_clean['Penthouse'].unique()\n",
    "df_clean.drop('Penthouse', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQdJM4irmZ60"
   },
   "outputs": [],
   "source": [
    "# Dropping description and real estate agent tag columns\n",
    "\n",
    "# We've gotten everything we need from these columns and they won't be useful for our ML model. \n",
    "df_clean.drop(['Real Estate Agent Tag', 'Description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkMi3wyUmZ61"
   },
   "outputs": [],
   "source": [
    "# Converting to integers\n",
    "df_clean['Bedrooms'].replace(' beds', '', regex=True, inplace=True)\n",
    "df_clean['Bedrooms'] = pd.to_numeric(df_clean['Bedrooms']).astype('Int64')\n",
    "\n",
    "df_clean['Bathrooms'].replace(' baths', '', regex=True, inplace=True)\n",
    "df_clean['Bathrooms'] = pd.to_numeric(df_clean['Bathrooms']).astype('Int64')\n",
    "\n",
    "df_clean['Toilets'].replace(' Toilets', '', regex=True, inplace=True)\n",
    "df_clean['Toilets'] = pd.to_numeric(df_clean['Toilets']).astype('Int64')\n",
    "\n",
    "df_clean['Price'].replace(',', '', regex=True, inplace=True)\n",
    "df_clean['Price'] = df_clean.Price.str.extract('(^\\d*)') # Doesn't seem like it's needed, maybe add back later\n",
    "df_clean['Price'] = pd.to_numeric(df_clean['Price'])\n",
    "\n",
    "# Code creates some NaN values for the \"Bathrooms\" and \"Toilets\" columns. Let's clean. \n",
    "df_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vk8MwnKbmZ61"
   },
   "outputs": [],
   "source": [
    "# Cleaning outliers\n",
    "# Let's clean outliers in terms of price to enhance the predictive capability of the model. \n",
    "# We attempt to use the standard 1.5*IQA method as high- and lowpass filters, but the low cutoff is then in negative price territory. \n",
    "# We make a judgement call and implement a cut of 20'000 Naira on the low end. \n",
    "\n",
    "Q1 = np.quantile(df_clean['Price'], 0.25)\n",
    "Q3 = np.quantile(df_clean['Price'], 0.75)\n",
    "Tolerance = 1.5*(Q3 - Q1)\n",
    "LoCut = Q1 - Tolerance\n",
    "HiCut = Q3 + Tolerance\n",
    "\n",
    "df_clean1 = df_clean.loc[df_clean['Price'] > 20000]\n",
    "df_clean2 = df_clean1.loc[df_clean['Price'] < HiCut]\n",
    "df_clean2['Price'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTKhKgtcmZ61"
   },
   "outputs": [],
   "source": [
    "# Location cleaning\n",
    "# Let's make the location column somewhat more useable by splitting it into state, area, and microlocation features.\n",
    "# Further geographical work can be found in the dedicated (GeoData/GeoPlots) Jupyter notebook\n",
    "\n",
    "# New column for states\n",
    "df_clean2[\"State\"] = df_clean2[\"Location\"].str.split().str[-1]\n",
    "\n",
    "# From exploratory data analysis, we see that Lagos is by far the most-represented area in the dataset. We focus on Lagos only. \n",
    "df_clean2 = df_clean2.loc[df_clean2[\"State\"]==\"Lagos\"]\n",
    "\n",
    "#New column for Areas\n",
    "df_clean2[\"Area\"] =  np.where(df_clean2.Location.str.contains(\"Victoria Island\"), \"Victoria Island\",\n",
    "                      np.where(df_clean2.Location.str.contains(\"Lagos Island\"), \"Ikoyi\",\n",
    "                      np.where(df_clean2.Location.str.contains(\"Ojota\"), \"Ogudu\",\n",
    "                       df_clean2[\"Location\"].str.split().str[-2])))\n",
    "#New column for microlocations\n",
    "df_clean2[\"Microlocation\"] = df_clean2[\"Location\"].str.rsplit(' ', 2).str[0]\n",
    "\n",
    "# We can drop the obsolete 'Location' Column. \n",
    "df_clean2.drop(['Location'], axis=1, inplace=True) \n",
    "\n",
    "# Let's create dummy variables for the 'Area' column\n",
    "Listte = np.arange(1,37)\n",
    "\n",
    "Area_number = {}\n",
    "for i,x in zip(df_clean2.Area.unique(),Listte ):\n",
    "    Area_number[i] = x\n",
    "    \n",
    "Area_dummy = []\n",
    "for i in range(len(df_clean2['Area'])):\n",
    "    Area_dummy.append(Area_number[df_clean2['Area'].values[i]])\n",
    "    \n",
    "df_clean2['Area Dummy'] = pd.DataFrame(Area_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGIlZZJcmZ62"
   },
   "outputs": [],
   "source": [
    "# Exporting\n",
    "\n",
    "# Index Cleaning\n",
    "df_clean2 = df_clean2.reset_index()\n",
    "df_clean2.drop(['index'], axis=1, inplace=True) \n",
    "\n",
    "# Export\n",
    "df_clean2.to_csv('NigeriaCleanedFinal.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
