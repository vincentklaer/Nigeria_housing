{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656fc570",
   "metadata": {},
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3432dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d51263c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating Features of the dataframe\n",
    "X = df.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"Price\", \"House\", \"State\", \"Area\", \"Microlocation\", \"Price_log\", \"location_append\", \"Longitude\", \"Latitude\", \"geometry\"], axis=1)\n",
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "debb1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Perfroming Cross Validation (KFold takes on the task of fitting the model as well as testing)\n",
    "folds = KFold(10, random_state = 11, shuffle = True)\n",
    "cv_results = cross_validate(RandomForestRegressor(), X = X, y = y, cv = folds, scoring = (\"r2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f057d0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53914420575889"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating mean r2 score\n",
    "cv_results[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8e29c",
   "metadata": {},
   "source": [
    "# Grid search optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca4ccb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Separating the model into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de02d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Creating a Grid of values to test for\n",
    "grid = { \n",
    "    'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750],\n",
    "    'max_features': ['sqrt','log2', 1.0, 2.0, 3.0,],\n",
    "    'max_depth' : [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "#Executing grid search function\n",
    "rf_GridSearchCV = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid, cv= 5, scoring=\"r2\")\n",
    "rf_GridSearchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing optimized hyperparameters \n",
    "print(rf_GridSearchCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#Calculating new score\n",
    "prediction_rf_GridSearchCV = rf_GridSearchCV.predict(X_test)\n",
    "print(metrics.r2_score(y_test, prediction_rf_GridSearchCV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5e343",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.space.transformers import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Defining Bayesian optimization function and selecting hyperparameters \n",
    "boptimize = BayesSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    {\n",
    "    'n_estimators': Integer(1, 1000),\n",
    "    'max_features': Integer(1, 12),\n",
    "    'max_depth': Integer(1, 100),\n",
    "    'min_samples_split': Integer(2, 100),\n",
    "    'min_samples_leaf': Integer(1, 100),\n",
    "    },\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "#Fitting the model\n",
    "boptimize.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ae616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing new hyperparameters \n",
    "print(boptimize.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db866afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calulating new score\n",
    "print(boptimize.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_objective, plot_histogram\n",
    "\n",
    "#Creating Partial Dependence plots of the objective function\n",
    "_ = plot_objective(boptimize.optimizer_results_[0],\n",
    "                   dimensions=[\"n_estimators\", \"max_features\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"],\n",
    "                   size=3.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befbd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "\n",
    "#Plotting the convergence trace\n",
    "plot_convergence(boptimize.optimizer_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6815eee",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model. that can use feature importance, with the best parameters\n",
    "rf_feature_model = RandomForestRegressor(max_depth = boptimize.best_params_['max_depth'], max_features = boptimize.best_params_['max_features'], min_samples_leaf = boptimize.best_params_['min_samples_leaf'], min_samples_split = boptimize.best_params_['min_samples_split'], n_estimators = boptimize.best_params_['n_estimators'])\n",
    "\n",
    "#Fitting the model\n",
    "rf_feature_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Feature Importances\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "fig.suptitle('Random Forest Regression Feature Importance', x=0.5, y=0.92, ha='center', size=18, fontweight = 'bold', font='Arial Nova')\n",
    "\n",
    "axes = sns.barplot(x=rf_feature_model.feature_importances_, y=X.columns)\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "axes.set_xlabel('Feature Importance', font='Arial Nova', size='15')\n",
    "axes.set_ylabel('Correlation', font='Arial Nova', size='15')\n",
    "\n",
    "xmajtick = np.arange(0, 15000000, 2000000)\n",
    "xmintick = np.arange(0, 15000000, 1000000)\n",
    "\n",
    "axes.grid(color=\"black\", which = \"major\", linestyle = \"--\", linewidth = 1, alpha = 0.5)\n",
    "axes.grid(color=\"gray\", which = \"minor\", linestyle = \":\", linewidth = 0.5, alpha = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e514ffd",
   "metadata": {},
   "source": [
    "# Residuals Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c05318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "# Create the visualizer\n",
    "rf_visualizer = ResidualsPlot(boptimize)\n",
    "\n",
    "# Fit the training data to the visualizer\n",
    "rf_visualizer.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "rf_visualizer.score(X_test, y_test)  \n",
    "\n",
    "# Finalize and render the figure\n",
    "rf_visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
